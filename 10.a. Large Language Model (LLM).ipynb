{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMcPql+YWjp1QpCRWRH00Bt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mahdi-Saadati/Advanced-Machine-Learning-and-Deep-Neural-Networks/blob/main/10.a.%20Large%20Language%20Model%20(LLM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\" align=\"right\">\n",
        "\n",
        "LLM (Large Language Model)\n",
        "\n",
        "۱. تعریف خیلی ساده\n",
        "\n",
        "یک LLM مثل یک مغز دیجیتالی خیلی بزرگ است که روی میلیون‌ها جمله و متن آموزش دیده تا بتواند متن جدید بسازد یا به سؤال‌ها پاسخ بدهد.\n",
        "\n",
        "مثال ساده:\n",
        "\n",
        "اگر به آن بنویسی:\n",
        "\"سلام، حال شما چطور است؟\"\n",
        "\n",
        "LLM می‌تواند پاسخ دهد:\n",
        "\"سلام! من خوبم، شما چطورید؟\"\n",
        "\n",
        "۲. چطور کار می‌کند؟\n",
        "\n",
        "۱. خواندن متن‌های زیادی: کتاب‌ها، مقاله‌ها، وب‌سایت‌ها.\n",
        "۲. یادگیری الگوها: مثلا تشخیص اینکه بعد از \"I love\" معمولاً چه کلماتی می‌آیند (\"AI\", \"music\" و …).\n",
        "۳. تولید متن جدید: وقتی از آن چیزی می‌پرسی، از همان الگوها استفاده می‌کند تا پاسخ بسازد.\n",
        "\n",
        "🔹 نکته: LLM واقعاً هوش ندارد، بلکه الگوهای زبان را یاد گرفته و پیش‌بینی می‌کند چه کلمه‌ای احتمالاً بعدی است.\n",
        "\n",
        "۳. چرا “Large” است؟\n",
        "\n",
        "Large = بزرگ\n",
        "\n",
        "میلیون‌ها یا حتی میلیاردها پارامتر دارد (اعدادی که مدل با آن‌ها یاد می‌گیرد چه چیزی بعد از چه چیزی می‌آید).\n",
        "\n",
        "هر چه مدل بزرگ‌تر باشد، می‌تواند متن پیچیده‌تر و منطقی‌تر بسازد.\n",
        "\n",
        "۴. مثال واقعی\n",
        "\n",
        "ChatGPT، GPT-4، و BERT همه نوعی LLM هستند.\n",
        "\n",
        "کاری که انجام می‌دهند:\n",
        "\n",
        "متن می‌خوانند\n",
        "\n",
        "الگوهای آن را یاد می‌گیرند\n",
        "\n",
        "پاسخ یا متن جدید تولید می‌کنند\n",
        "\n",
        "💡 خلاصه خیلی کوتاه:\n",
        "\n",
        "LLM یک مدل کامپیوتری است که مثل یک مغز بزرگ متنی عمل می‌کند: متن زیادی خوانده، یاد گرفته چه کلماتی معمولاً کنار هم می‌آیند و حالا می‌تواند متن جدید بسازد یا جواب سؤال بدهد.\n",
        "\n",
        "برای یک مثال ساده از Large Language Model (LLM) در پایتون، می‌توانیم از مدل‌های آماده مثل OpenAI GPT یا Hugging Face Transformers استفاده کنیم. من یک مثال با کتابخانه transformers می‌زنم که کاملاً محلی و ساده باشد.\n",
        "\n",
        "این مثال، یک متن کوتاه به مدل می‌دهد و مدل ادامه آن را تولید می‌کند:"
      ],
      "metadata": {
        "id": "fXKz2oLTyQj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# نصب کتابخانه مورد نیاز (اگر نصب نشده باشد)\n",
        "# pip install transformers torch\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# نام مدل (برای مثال از مدل سبک GPT-2 استفاده می‌کنیم)\n",
        "model_name = \"gpt2\"\n",
        "\n",
        "# بارگذاری توکنایزر و مدل\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# متن ورودی (prompt)\n",
        "prompt = \"Machine learning in healthcare is important because\"\n",
        "\n",
        "# تبدیل متن به توکن\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "# تولید متن توسط مدل\n",
        "outputs = model.generate(inputs[\"input_ids\"], max_length=50, num_return_sequences=1)\n",
        "\n",
        "# تبدیل توکن‌ها به متن خوانا\n",
        "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TsBeLiWx8yN",
        "outputId": "3bbcee26-e36f-44ff-9120-d0cabb53b17c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Machine learning in healthcare is important because it allows us to understand the health of patients and their care.\n",
            "\n",
            "The first step in this process is to understand the patient's health history. This is important because it allows us to understand the health of patients\n"
          ]
        }
      ]
    }
  ]
}