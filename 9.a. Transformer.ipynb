{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN5LDWAVtE1DXTPYcPmJAZ6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mahdi-Saadati/Advanced-Machine-Learning-and-Deep-Neural-Networks/blob/main/9.a.%20Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\" align=\"right\">\n",
        "\n",
        "شبکه ترنسفورمر (Transformer)\n",
        "\n",
        "1️⃣ ایده اصلی\n",
        "\n",
        "فرض کنید می‌خواهیم یک متن را پردازش کنیم، مثلاً جمله:\n",
        "\"من امروز به مدرسه رفتم\"\n",
        "\n",
        "هدف ما این است که مدل بتواند بفهمد ارتباط بین کلمات چیست، حتی اگر کلمات فاصله زیادی داشته باشند.\n",
        "\n",
        "قبل از Transformer، مدل‌های قدیمی مثل RNN یا LSTM کلمات را یکی یکی پردازش می‌کردند و اگر یک کلمه خیلی دور بود، یادگیری ارتباط سخت می‌شد.\n",
        "\n",
        "Transformer می‌گوید:\n",
        "\n",
        "\"چرا همه چیز را یکجا نبینیم و مستقیماً ارتباط بین هر کلمه با هر کلمه را بسنجیم؟\"\n",
        "\n",
        "2️⃣ بخش‌های کلیدی Transformer\n",
        "🔹 ورودی: کلمات → بردارها\n",
        "\n",
        "هر کلمه تبدیل می‌شود به یک عدد یا بردار عددی (مثل شناسه کلمه یا embedding).\n",
        "مثال: \"من\" → [0.1, 0.3, 0.5]\n",
        "\"مدرسه\" → [0.7, 0.2, 0.9]\n",
        "\n",
        "🔹 Attention (توجه)\n",
        "\n",
        "اینجاست که جادو اتفاق می‌افتد:\n",
        "\n",
        "به هر کلمه می‌گوید: \"به کدام کلمات دیگر جمله توجه کنم تا معنی‌ام را بهتر بفهمم؟\"\n",
        "\n",
        "مثال:\n",
        "\n",
        "کلمه \"رفتم\" بیشتر به \"مدرسه\" توجه می‌کند تا \"امروز\"، چون معنی رفتن به مقصد مرتبط است.\n",
        "\n",
        "این کار با محاسبه وزن‌ها بین همه کلمات انجام می‌شود.\n",
        "\n",
        "وزن زیاد = ارتباط قوی\n",
        "\n",
        "وزن کم = ارتباط ضعیف\n",
        "\n",
        "این بخش Self-Attention نام دارد.\n",
        "\n",
        "🔹 Feed-Forward (لایه پردازشی)\n",
        "\n",
        "بعد از Attention، هر کلمه با اطلاعاتی که از دیگر کلمات گرفته ترکیب می‌شود و از چند لایه ساده پردازش عبور می‌کند تا اطلاعات بهتر یاد گرفته شود.\n",
        "\n",
        "🔹 Positional Encoding\n",
        "\n",
        "چون Transformer همه کلمات را همزمان پردازش می‌کند، باید بداند ترتیب کلمات چیست.\n",
        "\n",
        "این کار با اضافه کردن یک بردار موقعیت به هر کلمه انجام می‌شود.\n",
        "مثال:\n",
        "\"من\" → [0.1,0.3,0.5] + position_0\n",
        "\"مدرسه\" → [0.7,0.2,0.9] + position_3\n",
        "\n",
        "🔹 Encoder و Decoder\n",
        "\n",
        "Encoder: متن ورودی را می‌فهمد و اطلاعات مهم را استخراج می‌کند.\n",
        "\n",
        "Decoder: بر اساس اطلاعات Encoder، متن خروجی می‌سازد (مثل ترجمه یا پاسخ).\n",
        "\n",
        "3️⃣ خلاصه بصری ساده\n",
        "ورودی متن → تبدیل به بردار → Attention (هر کلمه به همه نگاه می‌کند)\n",
        "→ لایه‌های پردازش → خروجی معنایی (یا ترجمه، یا پیش‌بینی کلمه بعدی)\n",
        "\n",
        "\n",
        "بزرگترین قدرت Transformer این است که می‌تواند ارتباطات دور بین کلمات را به راحتی یاد بگیرد، بدون نیاز به پردازش کلمه به کلمه.\n",
        "\n",
        "💡 مثال روزمره:\n",
        "فرض کن می‌خواهی بفهمی جمله‌ی \"علی که دیروز مریض بود امروز به مدرسه رفت\" چه معنایی دارد.\n",
        "\n",
        "Transformer می‌تواند بفهمد \"رفتن\" مربوط به \"علی\" و \"مدرسه\" است، حتی اگر کلمه‌ها فاصله زیادی داشته باشند."
      ],
      "metadata": {
        "id": "hZrWzh0BrukD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import TextVectorization, Input, Embedding, MultiHeadAttention, LayerNormalization, Dense\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "# 1. داده‌های اولیه: جملات انگلیسی و ترجمه فارسی\n",
        "eng_texts = [\n",
        "    \"I love AI\",                       # جمله انگلیسی\n",
        "    \"Deep learning is fun\",            # جمله انگلیسی\n",
        "    \"Transformers are powerful\",       # جمله انگلیسی\n",
        "]\n",
        "fa_texts = [\n",
        "    \"من هوش مصنوعی را دوست دارم\",        # ترجمه فارسی\n",
        "    \"یادگیری عمیق جذاب است\",             # ترجمه فارسی\n",
        "    \"ترنسفورمرها قدرتمند هستند\",          # ترجمه فارسی\n",
        "]\n",
        "\n",
        "# 2. آماده‌سازی ابزار بردارسازی متن (تبدیل کلمات → اعداد)\n",
        "max_len = 6  # حداکثر طول جمله (کلمات اضافه کوتاه یا پر می‌شوند)\n",
        "eng_vectorizer = TextVectorization(max_tokens=50, output_sequence_length=max_len)\n",
        "eng_vectorizer.adapt(eng_texts)  # ساخت واژگان انگلیسی\n",
        "fa_vectorizer = TextVectorization(max_tokens=50, output_sequence_length=max_len)\n",
        "fa_vectorizer.adapt(fa_texts)    # ساخت واژگان فارسی\n",
        "\n",
        "# واژگان (دیکشنری لغات)\n",
        "eng_vocab = eng_vectorizer.get_vocabulary()\n",
        "fa_vocab = fa_vectorizer.get_vocabulary()\n",
        "\n",
        "# 3. تبدیل جملات به توالی عددی\n",
        "eng_seq = eng_vectorizer(eng_texts).numpy()[:, :-1]  # ورودی مدل (encoder)\n",
        "fa_seq = fa_vectorizer(fa_texts).numpy()[:, 1:]      # خروجی مدل (decoder target, شیفت شده)\n",
        "\n",
        "# 4. تعریف مدل Transformer ساده\n",
        "embed_dim = 16   # اندازه بردار هر کلمه\n",
        "num_heads = 2    # تعداد هد در Multi-Head Attention\n",
        "ff_dim = 32      # اندازه لایه Feed Forward\n",
        "\n",
        "# --- Encoder ---\n",
        "encoder_inputs = Input(shape=(max_len-1,))  # ورودی جملات انگلیسی (اعداد)\n",
        "x = Embedding(input_dim=len(eng_vocab), output_dim=embed_dim)(encoder_inputs)  # تبدیل عدد → بردار\n",
        "attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(x, x) # Self-Attention روی انگلیسی\n",
        "x = LayerNormalization(epsilon=1e-6)(x + attn_output)  # نرمال‌سازی + اتصال باقی‌مانده (residual)\n",
        "ff = Dense(ff_dim, activation=\"relu\")(x)   # لایه Feed Forward\n",
        "ff = Dense(embed_dim)(ff)\n",
        "encoder_outputs = LayerNormalization(epsilon=1e-6)(x + ff)  # خروجی نهایی encoder\n",
        "\n",
        "# --- Decoder ---\n",
        "decoder_inputs = Input(shape=(max_len-1,))  # ورودی فارسی (shift شده)\n",
        "y = Embedding(input_dim=len(fa_vocab), output_dim=embed_dim)(decoder_inputs)  # عدد → بردار\n",
        "attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(y, encoder_outputs) # توجه به encoder\n",
        "y = LayerNormalization(epsilon=1e-6)(y + attn_output)\n",
        "ff = Dense(ff_dim, activation=\"relu\")(y)\n",
        "ff = Dense(embed_dim)(ff)\n",
        "decoder_outputs = LayerNormalization(epsilon=1e-6)(y + ff)  # خروجی decoder\n",
        "\n",
        "# --- Output layer ---\n",
        "outputs = Dense(len(fa_vocab), activation=\"softmax\")(decoder_outputs)  # پیش‌بینی کلمات فارسی\n",
        "\n",
        "# ساخت و کامپایل مدل\n",
        "model = Model([encoder_inputs, decoder_inputs], outputs)\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()  # نمایش ساختار مدل\n",
        "\n",
        "# 5. آموزش مدل روی داده‌های کوچک (500 تکرار برای نمونه کوچک)\n",
        "model.fit([eng_seq, fa_seq], np.expand_dims(fa_seq, -1), epochs=500, verbose=0)\n",
        "\n",
        "# 6. تست مدل روی یک جمله جدید\n",
        "test_sentence = \"I love AI\"  # جمله تست\n",
        "test_seq = eng_vectorizer([test_sentence]).numpy()[:, :-1]  # تبدیل به عدد\n",
        "decoder_input = np.zeros((1, max_len-1))  # ورودی اولیه decoder (شروع با صفرها)\n",
        "pred = model.predict([test_seq, decoder_input])  # پیش‌بینی کلمه به کلمه\n",
        "\n",
        "# انتخاب بیشترین احتمال برای هر کلمه\n",
        "pred_indices = np.argmax(pred[0], axis=-1)\n",
        "# بازگرداندن اعداد → کلمات فارسی\n",
        "pred_words = [fa_vocab[i] for i in pred_indices if i != 0]\n",
        "translation = \" \".join(pred_words)\n",
        "\n",
        "print(\"English:\", test_sentence)\n",
        "print(\"Predicted Persian:\", translation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NLWU9QYesTXc",
        "outputId": "f4fb3822-cffb-4939-f8c1-896fcbdeb49a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │        \u001b[38;5;34m192\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │      \u001b[38;5;34m2,160\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │         \u001b[38;5;34m32\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m544\u001b[0m │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │        \u001b[38;5;34m528\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│                     │                   │            │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │        \u001b[38;5;34m240\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │         \u001b[38;5;34m32\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │      \u001b[38;5;34m2,160\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │         \u001b[38;5;34m32\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m544\u001b[0m │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │        \u001b[38;5;34m528\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│                     │                   │            │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │         \u001b[38;5;34m32\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m15\u001b[0m)     │        \u001b[38;5;34m255\u001b[0m │ layer_normalizat… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,160</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,160</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│                     │                   │            │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">255</span> │ layer_normalizat… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,279\u001b[0m (28.43 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,279</span> (28.43 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,279\u001b[0m (28.43 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,279</span> (28.43 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "English: I love AI\n",
            "Predicted Persian: \n"
          ]
        }
      ]
    }
  ]
}