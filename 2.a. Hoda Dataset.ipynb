{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDQ9FgfSH1RfvYhjdYTmAH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mahdi-Saadati/Machine-Learning-2/blob/main/2.a.%20Hoda%20Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\" align=\"right\">\n",
        "معرفی مجموعه داده هدی و تغییر اندازه و شکل برای استفاده در الگوریتم‌های یادگیری ماشین\n",
        "\n",
        "معرفی مجموعه داده ارقام دستنویس هدی\n",
        "\n",
        "مجموعه ارقام دستنویس هدی که اولین مجموعه‌ی بزرگ ارقام دستنویس فارسی است، مشتمل بر ۱۰۲۳۵۳ نمونه دستنوشته سیاه سفید است. این مجموعه طی انجام یک پروژه‏ی کارشناسی ارشد درباره بازشناسی فرمهای دستنویس تهیه شده است. داده های این مجموعه از حدود ۱۲۰۰۰ فرم ثبت نام آزمون سراسری کارشناسی ارشد سال ۱۳۸۴ و آزمون کاردانی پیوسته‏ی دانشگاه جامع علمی کاربردی سال ۱۳۸۳ استخراج شده است.\n",
        "\n",
        "دیتاست (dataset)\n",
        "این مجموعه داده در قالب فایل mat متلب منتشر شده است."
      ],
      "metadata": {
        "id": "hZrWzh0BrukD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/Alireza-Akhavan/deeplearning-tensorflow2-notebooks/master/dataset.py\n",
        "!wget https://github.com/Alireza-Akhavan/deeplearning-tensorflow2-notebooks/raw/master/dataset/Data_hoda_full.mat -P dataset"
      ],
      "metadata": {
        "id": "NLWU9QYesTXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# مرحله 1: وارد کردن کتابخانه‌ها\n",
        "import keras  # کتابخانه‌ای برای ساخت شبکه‌های عصبی\n",
        "from keras.models import Sequential  # مدل دنباله‌ای ساده از لایه‌ها\n",
        "from keras.layers import Dense, Dropout, Activation  # انواع لایه‌هایی که به مدل اضافه می‌کنیم\n",
        "import numpy as np  # برای کار با اعداد و ماتریس‌ها\n",
        "from dataset import load_hoda  # تابعی برای بارگذاری داده‌های حروف فارسی\n",
        "\n",
        "np.random.seed(123)  # تنظیم یک عدد تصادفی ثابت، برای اینکه نتایج همیشه یکسان باشند\n",
        "\n",
        "# مرحله 2: بارگذاری داده‌ها (عکس‌های عدد فارسی) برای آموزش و آزمایش\n",
        "x_train_original, y_train_original, x_test_original, y_test_original = load_hoda()  # بارگذاری داده‌ها\n",
        "\n",
        "# مرحله 3: آماده‌سازی داده‌های ورودی\n",
        "x_train = np.array(x_train_original)  # تبدیل لیست آموزش به آرایه عددی\n",
        "x_test = np.array(x_test_original)    # تبدیل لیست آزمایش به آرایه عددی\n",
        "x_train = x_train.astype('float32')   # تبدیل داده‌ها به عدد اعشاری (برای دقت بیشتر)\n",
        "x_test = x_test.astype('float32')     # همین کار برای داده‌های آزمایش\n",
        "x_train /= 255  # نرمال‌سازی: عددها را به بازه بین ۰ تا ۱ می‌بریم\n",
        "x_test /= 255   # همین کار برای داده‌های آزمایش\n",
        "\n",
        "# مرحله 4: آماده‌سازی لیبل‌ها (برچسب‌های جواب درست)\n",
        "y_train = keras.utils.to_categorical(y_train_original, num_classes=10)  # تبدیل عددها به شکل یک‌در-ده\n",
        "y_test = keras.utils.to_categorical(y_test_original, num_classes=10)    # مثلاً عدد 3 تبدیل می‌شود به [0,0,0,1,0,0,0,0,0,0]\n",
        "\n",
        "# مرحله 5: تعریف مدل شبکه عصبی\n",
        "model = Sequential()  # شروع ساخت مدل ساده\n",
        "model.add(Dense(64, activation='relu', input_dim=25))  # یک لایه با 64 نورون، فعال‌سازی ReLU، ورودی 25 عدد\n",
        "model.add(Dense(10, activation='softmax'))  # خروجی با 10 نورون (برای ارقام 0 تا 9) با تابع softmax برای انتخاب بهترین جواب\n",
        "\n",
        "# مرحله 6: تنظیمات مدل قبل از آموزش\n",
        "model.compile(loss='categorical_crossentropy',  # نوع خطا را مشخص می‌کنیم\n",
        "              optimizer='rmsprop',              # روش یادگیری را مشخص می‌کنیم\n",
        "              metrics=['accuracy'])             # دقت مدل را هم بررسی می‌کنیم\n",
        "\n",
        "# مرحله 7: آموزش دادن مدل با داده‌های آموزشی\n",
        "model.fit(x_train, y_train,  # ورودی و خروجی داده‌های آموزش\n",
        "          epochs=30,         # چند بار همه داده‌ها آموزش داده شوند (۳۰ بار)\n",
        "          batch_size=64)     # چندتا چندتا به مدل داده شوند (۶۴ تا)\n",
        "\n",
        "# مرحله 8: ارزیابی مدل با داده‌های آزمایش\n",
        "loss, acc = model.evaluate(x_test, y_test)  # بررسی خطا و دقت مدل روی داده‌های آزمایشی\n",
        "print('\\nTesting loss: %.2f, acc: %.2f%%' % (loss, acc))  # چاپ نتیجه آزمایش\n",
        "\n",
        "# پیش‌بینی برچسب‌ها برای داده‌های آزمایش\n",
        "predictions = model.predict(x_test)  # پیش‌بینی احتمال هر کلاس برای هر ورودی\n",
        "predicted_classes = np.argmax(predictions, axis=1)  # انتخاب کلاسی که بیشترین احتمال را دارد\n",
        "print(\"predicted:\")  # چاپ جواب‌های پیش‌بینی‌شده\n",
        "print(predicted_classes)\n",
        "print(\"True Label:\")  # چاپ جواب‌های واقعی\n",
        "print(y_test_original)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryCACodY4cbY",
        "outputId": "e9795cb2-2540-4664-c127-9aaa6d8a303a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2080 - loss: 2.2530  \n",
            "Epoch 2/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3533 - loss: 1.9977 \n",
            "Epoch 3/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5071 - loss: 1.8271 \n",
            "Epoch 4/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6306 - loss: 1.6032 \n",
            "Epoch 5/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7279 - loss: 1.4314 \n",
            "Epoch 6/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8039 - loss: 1.2666 \n",
            "Epoch 7/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7982 - loss: 1.0955 \n",
            "Epoch 8/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8133 - loss: 0.9948 \n",
            "Epoch 9/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8254 - loss: 0.8940 \n",
            "Epoch 10/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8505 - loss: 0.7721 \n",
            "Epoch 11/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8581 - loss: 0.7124 \n",
            "Epoch 12/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8837 - loss: 0.6137 \n",
            "Epoch 13/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8653 - loss: 0.6079 \n",
            "Epoch 14/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8666 - loss: 0.5685 \n",
            "Epoch 15/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8930 - loss: 0.4837 \n",
            "Epoch 16/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8770 - loss: 0.5060 \n",
            "Epoch 17/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9037 - loss: 0.4244 \n",
            "Epoch 18/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9032 - loss: 0.4090 \n",
            "Epoch 19/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9066 - loss: 0.3914 \n",
            "Epoch 20/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9013 - loss: 0.3688 \n",
            "Epoch 21/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9083 - loss: 0.3652 \n",
            "Epoch 22/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9002 - loss: 0.3684 \n",
            "Epoch 23/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9018 - loss: 0.3592 \n",
            "Epoch 24/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9090 - loss: 0.3335 \n",
            "Epoch 25/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9062 - loss: 0.3191 \n",
            "Epoch 26/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9097 - loss: 0.3230 \n",
            "Epoch 27/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9094 - loss: 0.3007 \n",
            "Epoch 28/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9081 - loss: 0.3174 \n",
            "Epoch 29/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9288 - loss: 0.2728 \n",
            "Epoch 30/30\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9045 - loss: 0.3068 \n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9080 - loss: 0.3109 \n",
            "\n",
            "Testing loss: 0.33, acc: 0.91%\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "predicted:\n",
            "[7 2 3 8 5 5 4 7 3 2 0 8 8 0 3 9 3 6 7 4 0 3 6 3 9 2 7 5 2 9 2 5 5 8 9 2 5\n",
            " 1 4 8 8 4 7 2 1 2 7 9 0 3 7 2 7 5 2 9 8 2 9 8 8 6 6 6 7 6 2 4 2 4 4 5 9 1\n",
            " 8 4 0 5 6 2 4 3 2 7 7 7 7 1 8 1 7 8 7 7 8 9 7 2 3 1 0 2 9 6 3 5 5 0 0 9 6\n",
            " 7 9 3 9 9 8 7 9 2 5 2 5 5 9 6 9 2 0 3 7 9 5 2 9 0 4 1 8 2 2 3 5 2 9 3 8 2\n",
            " 7 0 9 9 0 7 6 2 4 4 9 3 7 0 7 1 9 4 7 3 4 1 5 6 7 9 1 3 5 4 5 7 4 1 3 3 1\n",
            " 1 3 3 8 9 6 7 7 2 3 0 1 0 9 5]\n",
            "True Label:\n",
            "[7 2 3 1 5 5 4 7 3 2 0 8 8 0 2 9 3 6 7 4 0 3 6 3 9 2 7 5 2 9 7 5 5 8 9 6 5\n",
            " 1 4 8 8 4 7 7 1 2 7 9 0 3 7 4 7 5 2 9 8 2 9 8 8 6 6 6 6 6 2 4 3 4 4 5 9 1\n",
            " 8 2 0 5 6 2 4 3 2 7 7 7 7 1 8 1 7 8 7 7 8 9 3 2 3 1 0 2 9 6 3 5 5 0 0 3 6\n",
            " 7 9 3 9 9 8 7 9 2 5 2 5 5 9 6 9 2 0 3 7 6 5 2 9 0 4 1 8 2 2 3 0 2 9 3 8 6\n",
            " 7 0 9 9 0 7 6 5 4 7 9 3 7 0 7 1 9 4 7 3 4 1 5 6 7 9 1 3 5 4 5 7 4 1 3 3 1\n",
            " 2 3 3 8 9 6 7 7 2 3 0 1 4 9 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_train_original[12].reshape(5, 5), cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8lhRlI_v8cAp",
        "outputId": "486b205a-9269-47fb-f155-63f4fc40fb27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGdCAYAAAAv9mXmAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAEWVJREFUeJzt3U9oXOfZ8OF7bCM5JNIQJbWDkNSEtrQEI5f4HyLQP7GaYEJIdl0EqrrdtMjBRptWm5qsZOgmpTbBNJBuahwaUAIB1zVuLRGIiSwjcAMJBAJVcW0lm5Es6DhI5118fPo+v7HdGdm3Zka6LpjFDGf03Bzj+XHOo7FLRVEUAQD32aZGDwDA+iQwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkGLLWi+4vLwcV69ejY6OjiiVSmu9PAD3oCiKWFhYiO7u7ti06e7XKGsemKtXr0Zvb+9aLwvAfTQ7Oxs9PT13PWbNA9PR0bHWSwLUrFKpNHqEpjY/Px+9vb01fZaveWDcFgOaWWdnZ6NHaAm1fJbb5AcghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUqwqMCdOnIjHH388tm7dGvv27YsPP/zwfs8FQIurOzBvvfVWjIyMxNGjR+Py5cuxc+fOeO6552Jubi5jPgBaVKkoiqKeN+zbty/27NkTx48fj4iI5eXl6O3tjVdeeSV+/etf/9f3z8/PR7lcXt20AMnq/EjccP7vZ3ilUonOzs67HlvXFczNmzdjeno6BgcH/98P2LQpBgcH44MPPljdtACsS1vqOfiLL76IpaWl2L59+y2vb9++PT7++OPbvqdarUa1Wl15Pj8/v4oxAWg16b9FNjY2FuVyeeXR29ubvSQATaCuwDz66KOxefPmuH79+i2vX79+PR577LHbvmd0dDQqlcrKY3Z2dvXTAtAy6gpMW1tb7Nq1K86fP7/y2vLycpw/fz4GBgZu+5729vbo7Oy85QHA+lfXHkxExMjISAwNDcXu3btj79698dprr8Xi4mIcPHgwYz4AWlTdgfnxj38cn3/+efzmN7+Ja9euxXe/+934y1/+8pWNfwA2trq/B3OvfA8GaGa+B3N3ad+DAYBaCQwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkGJLoxauVCrR2dnZqOVbwtWrVxs9Qkvo7u5u9AisI/7e3d3CwkLNx7qCASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0CKugMzOTkZL7zwQnR3d0epVIp33nknYSwAWl3dgVlcXIydO3fGiRMnMuYBYJ3YUu8bDhw4EAcOHMiYBYB1xB4MACnqvoKpV7VajWq1uvJ8fn4+e0kAmkD6FczY2FiUy+WVR29vb/aSADSB9MCMjo5GpVJZeczOzmYvCUATSL9F1t7eHu3t7dnLANBk6g7MjRs34tNPP115/tlnn8XMzEx0dXVFX1/ffR0OgNZVd2AuXboUP/zhD1eej4yMRETE0NBQ/PGPf7xvgwHQ2uoOzA9+8IMoiiJjFgDWEd+DASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKbY0auFyudyopVtGURSNHqEllEqlRo8A3IYrGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkqCswY2NjsWfPnujo6Iht27bFSy+9FJ988knWbAC0sLoCMzExEcPDw3Hx4sU4d+5cfPnll/Hss8/G4uJi1nwAtKhSURTFat/8+eefx7Zt22JiYiK+973v1fSe+fn5KJfLq11yQ7mHP5oNpVQqNXoE2HAqlUp0dnbe9Zgt97pARERXV9cdj6lWq1GtVleez8/P38uSALSIVW/yLy8vx5EjR+Lpp5+OHTt23PG4sbGxKJfLK4/e3t7VLglAC1n1LbJf/vKXcebMmXj//fejp6fnjsfd7gpGZGrjFllt3CKDtZd2i+zQoUPx3nvvxeTk5F3jEhHR3t4e7e3tq1kGgBZWV2CKoohXXnklxsfH48KFC/HEE09kzQVAi6srMMPDw3Hq1Kl49913o6OjI65duxYREeVyOR544IGUAQFoTXXtwdzpXvebb74ZP/3pT2v6GX5NuXb2YGpjDwbW3n3fg/GBB0Ct/FtkAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJCirsC8/vrr0d/fH52dndHZ2RkDAwNx5syZrNkAaGF1BaanpyeOHTsW09PTcenSpXjmmWfixRdfjI8++ihrPgBaVKkoiuJefkBXV1f89re/jZ///Oc1HT8/Px/lcvleltww7vGPZsMolUqNHgE2nEqlEp2dnXc9Zstqf/jS0lL8+c9/jsXFxRgYGLjjcdVqNarV6srz+fn51S4JQAupe5P/ypUr8dBDD0V7e3v84he/iPHx8XjyySfvePzY2FiUy+WVR29v7z0NDEBrqPsW2c2bN+Of//xnVCqVePvtt+ONN96IiYmJO0bmdlcwIlMbt8hq4xYZrL1abpHd8x7M4OBgfOMb34iTJ0/WdLw9mNoJTG0EBtZeLYG55+/BLC8v33KFAgARdW7yj46OxoEDB6Kvry8WFhbi1KlTceHChTh79mzWfAC0qLoCMzc3Fz/5yU/i3//+d5TL5ejv74+zZ8/Gj370o6z5AGhR97wHUy97MLWzB1MbezCw9tZkDwYAbkdgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUWxo9AHdWKpUaPUJLOHr0aKNHaAmvvvpqo0dgg3EFA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAU9xSYY8eORalUiiNHjtyncQBYL1YdmKmpqTh58mT09/ffz3kAWCdWFZgbN27Eyy+/HH/4wx/i4Ycfvt8zAbAOrCoww8PD8fzzz8fg4OB/PbZarcb8/PwtDwDWvy31vuH06dNx+fLlmJqaqun4sbGxePXVV+seDIDWVtcVzOzsbBw+fDj+9Kc/xdatW2t6z+joaFQqlZXH7OzsqgYFoLXUdQUzPT0dc3Nz8dRTT628trS0FJOTk3H8+PGoVquxefPmW97T3t4e7e3t92daAFpGXYHZv39/XLly5ZbXDh48GN/5znfiV7/61VfiAsDGVVdgOjo6YseOHbe89uCDD8YjjzzyldcB2Nh8kx+AFHX/Ftn/duHChfswBgDrjSsYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASDFlrVesCiKtV6Sda5arTZ6BNhwavksLxVr/In/r3/9K3p7e9dySQDus9nZ2ejp6bnrMWsemOXl5bh69Wp0dHREqVRay6XvaH5+Pnp7e2N2djY6OzsbPU5Tco5q4zzVxnmqTTOep6IoYmFhIbq7u2PTprvvsqz5LbJNmzb91+o1SmdnZ9P8ITYr56g2zlNtnKfaNNt5KpfLNR1nkx+AFAIDQAqBiYj29vY4evRotLe3N3qUpuUc1cZ5qo3zVJtWP09rvskPwMbgCgaAFAIDQAqBASCFwACQYsMH5sSJE/H444/H1q1bY9++ffHhhx82eqSmMzk5GS+88EJ0d3dHqVSKd955p9EjNZ2xsbHYs2dPdHR0xLZt2+Kll16KTz75pNFjNZ3XX389+vv7V744ODAwEGfOnGn0WE3v2LFjUSqV4siRI40epS4bOjBvvfVWjIyMxNGjR+Py5cuxc+fOeO6552Jubq7RozWVxcXF2LlzZ5w4caLRozStiYmJGB4ejosXL8a5c+fiyy+/jGeffTYWFxcbPVpT6enpiWPHjsX09HRcunQpnnnmmXjxxRfjo48+avRoTWtqaipOnjwZ/f39jR6lfsUGtnfv3mJ4eHjl+dLSUtHd3V2MjY01cKrmFhHF+Ph4o8doenNzc0VEFBMTE40epek9/PDDxRtvvNHoMZrSwsJC8a1vfas4d+5c8f3vf784fPhwo0eqy4a9grl582ZMT0/H4ODgymubNm2KwcHB+OCDDxo4GetBpVKJiIiurq4GT9K8lpaW4vTp07G4uBgDAwONHqcpDQ8Px/PPP3/L51QrWfN/7LJZfPHFF7G0tBTbt2+/5fXt27fHxx9/3KCpWA+Wl5fjyJEj8fTTT8eOHTsaPU7TuXLlSgwMDMR//vOfeOihh2J8fDyefPLJRo/VdE6fPh2XL1+OqampRo+yahs2MJBleHg4/vGPf8T777/f6FGa0re//e2YmZmJSqUSb7/9dgwNDcXExITI/H9mZ2fj8OHDce7cudi6dWujx1m1DRuYRx99NDZv3hzXr1+/5fXr16/HY4891qCpaHWHDh2K9957LyYnJ5v2v6VotLa2tvjmN78ZERG7du2Kqamp+N3vfhcnT55s8GTNY3p6Oubm5uKpp55aeW1paSkmJyfj+PHjUa1WY/PmzQ2csDYbdg+mra0tdu3aFefPn195bXl5Oc6fP+9+MHUriiIOHToU4+Pj8be//S2eeOKJRo/UMpaXl/231//L/v3748qVKzEzM7Py2L17d7z88ssxMzPTEnGJ2MBXMBERIyMjMTQ0FLt37469e/fGa6+9FouLi3Hw4MFGj9ZUbty4EZ9++unK888++yxmZmaiq6sr+vr6GjhZ8xgeHo5Tp07Fu+++Gx0dHXHt2rWI+D//MdMDDzzQ4Omax+joaBw4cCD6+vpiYWEhTp06FRcuXIizZ882erSm0tHR8ZX9uwcffDAeeeSR1trXa/SvsTXa73//+6Kvr69oa2sr9u7dW1y8eLHRIzWdv//970VEfOUxNDTU6NGaxu3OT0QUb775ZqNHayo/+9nPiq9//etFW1tb8bWvfa3Yv39/8de//rXRY7WEVvw1Zf9cPwApNuweDAC5BAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEgxf8A1dMRpYROSnUAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}